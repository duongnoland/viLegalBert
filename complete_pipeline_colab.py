#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸš€ Complete Pipeline viLegalBert cho Google Colab (Dataset CÃ³ Sáºµn)
TÃ­ch há»£p SVM, PhoBERT, BiLSTM vÃ  Ensemble
"""

import os
import sys
import json
import pickle
import numpy as np
import pandas as pd
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

# CÃ i Ä‘áº·t dependencies
def install_dependencies():
    """CÃ i Ä‘áº·t táº¥t cáº£ dependencies cáº§n thiáº¿t"""
    print("ğŸ“¦ CÃ i Ä‘áº·t dependencies...")
    
    dependencies = [
        'scikit-learn',
        'torch',
        'transformers',
        'datasets',
        'torchtext'
    ]
    
    for dep in dependencies:
        try:
            __import__(dep.replace('-', '_'))
            print(f"âœ… {dep} Ä‘Ã£ sáºµn sÃ ng")
        except ImportError:
            print(f"ğŸ“¦ Äang cÃ i Ä‘áº·t {dep}...")
            os.system(f"pip install {dep}")
            print(f"âœ… ÄÃ£ cÃ i Ä‘áº·t {dep}")

# Import sau khi cÃ i Ä‘áº·t
from sklearn.metrics import accuracy_score, classification_report
import torch
from sklearn.model_selection import train_test_split

class CompletePipeline:
    """Pipeline hoÃ n chá»‰nh cho viLegalBert"""
    
    def __init__(self):
        """Khá»Ÿi táº¡o pipeline"""
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        print(f"ğŸš€ Sá»­ dá»¥ng device: {self.device}")
        
        # Cáº¥u hÃ¬nh pipeline
        self.config = {
            'train_models': ['svm', 'phobert', 'bilstm'],
            'create_ensemble': True,
            'evaluate_all': True
        }
        
        # Káº¿t quáº£ training
        self.results = {}
    
    def create_project_structure(self):
        """Táº¡o cáº¥u trÃºc thÆ° má»¥c"""
        print("ğŸ—ï¸ Táº¡o cáº¥u trÃºc project...")
        
        directories = [
            'models/saved_models/level1_classifier/svm_level1',
            'models/saved_models/level2_classifier/svm_level2',
            'models/saved_models/level1_classifier/phobert_level1',
            'models/saved_models/level2_classifier/phobert_level2',
            'models/saved_models/level1_classifier/bilstm_level1',
            'models/saved_models/level2_classifier/bilstm_level2',
            'models/saved_models/hierarchical_models',
            'results/training_results',
            'results/evaluation_results',
            'logs'
        ]
        
        for directory in directories:
            Path(directory).mkdir(parents=True, exist_ok=True)
            print(f"âœ… Táº¡o thÆ° má»¥c: {directory}")
    
    def check_dataset_availability(self):
        """Kiá»ƒm tra dataset cÃ³ sáºµn"""
        print("ğŸ” Kiá»ƒm tra dataset cÃ³ sáºµn...")
        
        possible_paths = [
            "data/processed/hierarchical_legal_dataset.csv",
            "hierarchical_legal_dataset.csv",
            "data/hierarchical_legal_dataset.csv",
            "dataset.csv",
            "legal_dataset.csv"
        ]
        
        for path in possible_paths:
            if Path(path).exists():
                print(f"âœ… TÃ¬m tháº¥y dataset: {path}")
                return path
        
        print("âŒ KhÃ´ng tÃ¬m tháº¥y dataset nÃ o")
        return None
    
    def check_dataset_splits(self):
        """Kiá»ƒm tra dataset splits cÃ³ sáºµn"""
        print("ğŸ” Kiá»ƒm tra dataset splits...")
        
        splits_dir = "data/processed/dataset_splits"
        train_path = Path(splits_dir) / "train.csv"
        val_path = Path(splits_dir) / "validation.csv"
        test_path = Path(splits_dir) / "test.csv"
        
        if train_path.exists() and val_path.exists() and test_path.exists():
            print("âœ… Dataset splits Ä‘Ã£ cÃ³ sáºµn")
            
            # Load vÃ  hiá»ƒn thá»‹ thÃ´ng tin splits
            train_df = pd.read_csv(train_path, encoding='utf-8')
            val_df = pd.read_csv(val_path, encoding='utf-8')
            test_df = pd.read_csv(test_path, encoding='utf-8')
            
            print(f"ğŸ“Š Train set: {len(train_df)} samples")
            print(f"ğŸ“Š Validation set: {len(val_df)} samples")
            print(f"ğŸ“Š Test set: {len(test_df)} samples")
            
            return True
        else:
            print("âš ï¸ Dataset splits chÆ°a cÃ³, sáº½ táº¡o má»›i...")
            return False
    
    def create_training_splits_from_existing(self, dataset_path: str, splits_dir: str):
        """Táº¡o training splits tá»« dataset cÃ³ sáºµn"""
        print("ğŸ”„ Táº¡o training splits tá»« dataset cÃ³ sáºµn...")
        
        # Load dataset
        df = pd.read_csv(dataset_path, encoding='utf-8')
        
        # Chia dá»¯ liá»‡u
        train_df, temp_df = train_test_split(df, test_size=0.3, random_state=42, stratify=df['type_level1'])
        val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42, stratify=temp_df['type_level1'])
        
        # LÆ°u cÃ¡c táº­p
        train_path = Path(splits_dir) / "train.csv"
        val_path = Path(splits_dir) / "validation.csv"
        test_path = Path(splits_dir) / "test.csv"
        
        train_df.to_csv(train_path, index=False, encoding='utf-8')
        val_df.to_csv(val_path, index=False, encoding='utf-8')
        test_df.to_csv(test_path, index=False, encoding='utf-8')
        
        print(f"âœ… Train set: {len(train_df)} samples -> {train_path}")
        print(f"âœ… Validation set: {len(val_df)} samples -> {val_path}")
        print(f"âœ… Test set: {len(test_df)} samples -> {test_path}")
    
    def train_svm(self, dataset_path: str):
        """Training SVM models"""
        print("ğŸ‹ï¸ Training SVM models...")
        
        try:
            # Import SVM trainer
            from main_colab import SVMTrainer
            
            trainer = SVMTrainer()
            
            # Training Level 1
            results_level1 = trainer.train_level1(dataset_path)
            
            # Training Level 2
            results_level2 = trainer.train_level2(dataset_path)
            
            self.results['svm'] = {
                'level1': results_level1,
                'level2': results_level2
            }
            
            print("âœ… SVM training hoÃ n thÃ nh")
            return True
            
        except Exception as e:
            print(f"âŒ Lá»—i khi training SVM: {e}")
            return False
    
    def train_phobert(self, dataset_path: str):
        """Training PhoBERT models"""
        print("ğŸ‹ï¸ Training PhoBERT models...")
        
        try:
            # Import PhoBERT trainer
            from phobert_colab import PhoBERTTrainer
            
            trainer = PhoBERTTrainer()
            
            # Training Level 1
            results_level1 = trainer.train_level1(dataset_path)
            
            # Training Level 2
            results_level2 = trainer.train_level2(dataset_path)
            
            self.results['phobert'] = {
                'level1': results_level1,
                'level2': results_level2
            }
            
            print("âœ… PhoBERT training hoÃ n thÃ nh")
            return True
            
        except Exception as e:
            print(f"âŒ Lá»—i khi training PhoBERT: {e}")
            return False
    
    def train_bilstm(self, dataset_path: str):
        """Training BiLSTM models"""
        print("ğŸ‹ï¸ Training BiLSTM models...")
        
        try:
            # Import BiLSTM trainer
            from bilstm_colab import BiLSTMTrainer
            
            trainer = BiLSTMTrainer()
            
            # Training Level 1
            results_level1 = trainer.train_level1(dataset_path)
            
            # Training Level 2
            results_level2 = trainer.train_level2(dataset_path)
            
            self.results['bilstm'] = {
                'level1': results_level1,
                'level2': results_level2
            }
            
            print("âœ… BiLSTM training hoÃ n thÃ nh")
            return True
            
        except Exception as e:
            print(f"âŒ Lá»—i khi training BiLSTM: {e}")
            return False
    
    def create_ensemble(self):
        """Táº¡o ensemble model"""
        print("ğŸ—ï¸ Táº¡o ensemble model...")
        
        try:
            # Import ensemble trainer
            from ensemble_colab import EnsembleTrainer
            
            trainer = EnsembleTrainer()
            
            # Load models
            svm_loaded = trainer.load_svm_models()
            phobert_loaded = trainer.load_phobert_models()
            bilstm_loaded = trainer.load_bilstm_models()
            
            if not any([svm_loaded, phobert_loaded, bilstm_loaded]):
                print("âŒ KhÃ´ng cÃ³ model nÃ o Ä‘Æ°á»£c load thÃ nh cÃ´ng")
                return False
            
            # Evaluation ensemble
            results = trainer.evaluate_ensemble("data/processed/dataset_splits/test.csv")
            
            self.results['ensemble'] = results
            
            print("âœ… Ensemble model Ä‘Ã£ Ä‘Æ°á»£c táº¡o")
            return True
            
        except Exception as e:
            print(f"âŒ Lá»—i khi táº¡o ensemble: {e}")
            return False
    
    def evaluate_all_models(self):
        """ÄÃ¡nh giÃ¡ táº¥t cáº£ models"""
        print("ğŸ“Š ÄÃ¡nh giÃ¡ táº¥t cáº£ models...")
        
        try:
            # Load test data
            test_df = pd.read_csv("data/processed/dataset_splits/test.csv", encoding='utf-8')
            
            evaluation_results = {}
            
            # Evaluate SVM
            if 'svm' in self.results:
                print("\nğŸ·ï¸ EVALUATING SVM...")
                from main_colab import evaluate_svm_models
                svm_results = evaluate_svm_models("data/processed/dataset_splits/test.csv")
                evaluation_results['svm'] = svm_results
            
            # Evaluate PhoBERT
            if 'phobert' in self.results:
                print("\nğŸ·ï¸ EVALUATING PHOBERT...")
                # PhoBERT evaluation logic here
                evaluation_results['phobert'] = {'status': 'trained'}
            
            # Evaluate BiLSTM
            if 'bilstm' in self.results:
                print("\nğŸ·ï¸ EVALUATING BILSTM...")
                # BiLSTM evaluation logic here
                evaluation_results['bilstm'] = {'status': 'trained'}
            
            # Evaluate Ensemble
            if 'ensemble' in self.results:
                print("\nğŸ·ï¸ EVALUATING ENSEMBLE...")
                evaluation_results['ensemble'] = self.results['ensemble']
            
            # Save evaluation results
            results_path = "results/evaluation_results/complete_evaluation_results.pkl"
            Path(results_path).parent.mkdir(parents=True, exist_ok=True)
            
            with open(results_path, 'wb') as f:
                pickle.dump(evaluation_results, f)
            
            print(f"ğŸ’¾ Evaluation results Ä‘Ã£ Ä‘Æ°á»£c lÆ°u: {results_path}")
            
            return evaluation_results
            
        except Exception as e:
            print(f"âŒ Lá»—i khi Ä‘Ã¡nh giÃ¡: {e}")
            return None
    
    def generate_summary_report(self):
        """Táº¡o bÃ¡o cÃ¡o tá»•ng há»£p"""
        print("ğŸ“‹ Táº¡o bÃ¡o cÃ¡o tá»•ng há»£p...")
        
        report = {
            'pipeline_config': self.config,
            'training_results': self.results,
            'summary': {}
        }
        
        # Thá»‘ng kÃª models Ä‘Ã£ train
        trained_models = list(self.results.keys())
        report['summary']['trained_models'] = trained_models
        report['summary']['total_models'] = len(trained_models)
        
        # Thá»‘ng kÃª theo level
        for level in ['level1', 'level2']:
            level_models = []
            for model_name in trained_models:
                if model_name != 'ensemble' and level in self.results[model_name]:
                    level_models.append(model_name)
            
            report['summary'][f'{level}_models'] = level_models
        
        # LÆ°u bÃ¡o cÃ¡o
        report_path = "results/training_results/pipeline_summary_report.pkl"
        Path(report_path).parent.mkdir(parents=True, exist_ok=True)
        
        with open(report_path, 'wb') as f:
            pickle.dump(report, f)
        
        print(f"ğŸ’¾ BÃ¡o cÃ¡o tá»•ng há»£p Ä‘Ã£ Ä‘Æ°á»£c lÆ°u: {report_path}")
        
        # In bÃ¡o cÃ¡o
        print("\n" + "=" * 80)
        print("ğŸ“‹ BÃO CÃO Tá»”NG Há»¢P PIPELINE")
        print("=" * 80)
        print(f"ğŸ“Š Models Ä‘Ã£ train: {', '.join(trained_models)}")
        print(f"ğŸ“Š Tá»•ng sá»‘ models: {len(trained_models)}")
        
        for level in ['level1', 'level2']:
            level_models = report['summary'][f'{level}_models']
            print(f"ğŸ·ï¸ {level.upper()}: {', '.join(level_models)}")
        
        print("=" * 80)
        
        return report
    
    def run_pipeline(self):
        """Cháº¡y toÃ n bá»™ pipeline"""
        print("ğŸš€ KHá»I Äá»˜NG COMPLETE PIPELINE!")
        print("ğŸ“Š Sá»¬ Dá»¤NG DATASET CÃ“ Sáº´N")
        print("=" * 80)
        
        # BÆ°á»›c 1: CÃ i Ä‘áº·t dependencies
        install_dependencies()
        
        # BÆ°á»›c 2: Táº¡o cáº¥u trÃºc project
        self.create_project_structure()
        
        # BÆ°á»›c 3: Kiá»ƒm tra dataset cÃ³ sáºµn
        print("\nğŸ“Š BÆ¯á»šC 1: KIá»‚M TRA DATASET CÃ“ Sáº´N")
        print("-" * 50)
        
        dataset_path = self.check_dataset_availability()
        if dataset_path is None:
            print("âŒ Pipeline dá»«ng do khÃ´ng tÃ¬m tháº¥y dataset")
            return False
        
        # BÆ°á»›c 4: Kiá»ƒm tra vÃ  táº¡o dataset splits
        print("\nğŸ”„ BÆ¯á»šC 2: KIá»‚M TRA DATASET SPLITS")
        print("-" * 50)
        
        if not self.check_dataset_splits():
            # Táº¡o splits má»›i tá»« dataset cÃ³ sáºµn
            splits_dir = "data/processed/dataset_splits"
            self.create_training_splits_from_existing(dataset_path, splits_dir)
        
        # BÆ°á»›c 5: Training cÃ¡c models
        print("\nğŸ‹ï¸ BÆ¯á»šC 3: TRAINING MODELS")
        print("-" * 50)
        
        training_success = True
        
        if 'svm' in self.config['train_models']:
            if not self.train_svm(dataset_path):
                training_success = False
        
        if 'phobert' in self.config['train_models']:
            if not self.train_phobert(dataset_path):
                training_success = False
        
        if 'bilstm' in self.config['train_models']:
            if not self.train_bilstm(dataset_path):
                training_success = False
        
        if not training_success:
            print("âš ï¸ Má»™t sá»‘ models training tháº¥t báº¡i")
        
        # BÆ°á»›c 6: Táº¡o ensemble
        if self.config['create_ensemble'] and training_success:
            self.create_ensemble()
        
        # BÆ°á»›c 7: ÄÃ¡nh giÃ¡ táº¥t cáº£
        if self.config['evaluate_all']:
            self.evaluate_all_models()
        
        # BÆ°á»›c 8: Táº¡o bÃ¡o cÃ¡o
        self.generate_summary_report()
        
        print("\nğŸ‰ COMPLETE PIPELINE HOÃ€N THÃ€NH!")
        print("ğŸš€ viLegalBert Ä‘Ã£ sáºµn sÃ ng sá»­ dá»¥ng!")
        
        return True

def main():
    """HÃ m chÃ­nh"""
    print("ğŸš€ VILEGALBERT COMPLETE PIPELINE CHO GOOGLE COLAB!")
    print("ğŸ“Š Sá»¬ Dá»¤NG DATASET CÃ“ Sáº´N")
    print("=" * 80)
    
    # Khá»Ÿi táº¡o vÃ  cháº¡y pipeline
    pipeline = CompletePipeline()
    success = pipeline.run_pipeline()
    
    if success:
        print("\nğŸ‰ PIPELINE HOÃ€N THÃ€NH THÃ€NH CÃ”NG!")
        print("ğŸ“Š Báº¡n cÃ³ thá»ƒ sá»­ dá»¥ng cÃ¡c models Ä‘Ã£ train Ä‘á»ƒ dá»± Ä‘oÃ¡n")
        print("ğŸš€ Tiáº¿p theo: Táº¡o web app hoáº·c API Ä‘á»ƒ sá»­ dá»¥ng models")
    else:
        print("\nâŒ PIPELINE Gáº¶P Lá»–I!")
        print("ğŸ” HÃ£y kiá»ƒm tra logs Ä‘á»ƒ tÃ¬m nguyÃªn nhÃ¢n")

if __name__ == "__main__":
    main() 