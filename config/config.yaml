# üéØ C·∫•u h√¨nh ch√≠nh d·ª± √°n viLegalBert
# Ph√¢n lo·∫°i vƒÉn b·∫£n ph√°p lu·∫≠t Vi·ªát Nam v·ªõi ki·∫øn tr√∫c 2 t·∫ßng

# ============================================================================
# C·∫§U H√åNH CHUNG
# ============================================================================
project:
  name: "viLegalBert"
  version: "1.0.0"
  description: "M√¥ h√¨nh ph√¢n lo·∫°i vƒÉn b·∫£n ph√°p lu·∫≠t Vi·ªát Nam"
  author: "Your Name"
  date: "2025-08-17"

# ============================================================================
# ƒê∆Ø·ªúNG D·∫™N D·ªÆ LI·ªÜU
# ============================================================================
data:
  raw_data_path: "data/raw/vbpl_crawl.json"
  processed_data_path: "data/processed/"
  embeddings_path: "data/embeddings/"
  external_data_path: "data/external/"
  
  # C·∫•u h√¨nh dataset
  target_size: 10000  # S·ªë l∆∞·ª£ng samples m·ª•c ti√™u
  train_split: 0.7    # T·ª∑ l·ªá training
  val_split: 0.15     # T·ª∑ l·ªá validation
  test_split: 0.15    # T·ª∑ l·ªá test

# ============================================================================
# C·∫§U H√åNH M√î H√åNH
# ============================================================================
model:
  # PhoBERT
  phobert:
    model_name: "vinai/phobert-base"
    max_length: 512
    dropout: 0.1
    
  # BiLSTM
  bilstm:
    hidden_size: 256
    num_layers: 2
    dropout: 0.2
    bidirectional: true
    
  # SVM
  svm:
    kernel: "rbf"
    C: 1.0
    gamma: "scale"
    max_features: 10000
    ngram_range: [1, 3]
    
  # Hierarchical Classifier
  hierarchical:
    level1_classes: 10  # S·ªë lo·∫°i vƒÉn b·∫£n c∆° b·∫£n
    level2_classes: 15  # S·ªë domain ph√°p l√Ω
    use_attention: true
    attention_heads: 8

# ============================================================================
# C·∫§U H√åNH TRAINING
# ============================================================================
training:
  # Hyperparameters
  batch_size: 16
  learning_rate: 2e-5
  num_epochs: 10
  warmup_steps: 100
  
  # Optimizer
  optimizer: "AdamW"
  weight_decay: 0.01
  
  # Scheduler
  scheduler: "linear"
  
  # Early stopping
  patience: 3
  min_delta: 0.001
  
  # Checkpointing
  save_steps: 500
  eval_steps: 500
  save_total_limit: 3

# ============================================================================
# C·∫§U H√åNH EVALUATION
# ============================================================================
evaluation:
  metrics: ["accuracy", "precision", "recall", "f1", "confusion_matrix"]
  eval_batch_size: 32
  
# ============================================================================
# C·∫§U H√åNH LOGGING
# ============================================================================
logging:
  level: "INFO"
  log_dir: "logs/"
  tensorboard: true
  
# ============================================================================
# C·∫§U H√åNH HARDWARE
# ============================================================================
hardware:
  device: "auto"  # auto, cuda, cpu
  num_workers: 4
  pin_memory: true
  
# ============================================================================
# C·∫§U H√åNH REPRODUCIBILITY
# ============================================================================
reproducibility:
  seed: 42
  deterministic: true 