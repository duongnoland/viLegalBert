#!/usr/bin/env python3
# -*- coding:utf-8 -*-
"""
ğŸ‹ï¸ Ensemble Trainer cho Google Colab
Káº¿t há»£p SVM, PhoBERT vÃ  BiLSTM cho phÃ¢n loáº¡i vÄƒn báº£n phÃ¡p luáº­t
"""

import os
import sys
import json
import pickle
import numpy as np
import pandas as pd
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

# CÃ i Ä‘áº·t dependencies
def install_deps():
    try:
        import sklearn
        print("âœ… scikit-learn Ä‘Ã£ sáºµn sÃ ng")
    except:
        os.system("pip install scikit-learn")
        print("ğŸ“¦ ÄÃ£ cÃ i Ä‘áº·t scikit-learn")
    
    try:
        import torch
        print("âœ… PyTorch Ä‘Ã£ sáºµn sÃ ng")
    except:
        os.system("pip install torch")
        print("ğŸ“¦ ÄÃ£ cÃ i Ä‘áº·t PyTorch")
    
    try:
        import transformers
        print("âœ… transformers Ä‘Ã£ sáºµn sÃ ng")
    except:
        os.system("pip install transformers")
        print("ğŸ“¦ ÄÃ£ cÃ i Ä‘áº·t transformers")

# Import sau khi cÃ i Ä‘áº·t
from sklearn.ensemble import VotingClassifier
from sklearn.metrics import accuracy_score, classification_report
from sklearn.model_selection import train_test_split
import torch
import numpy as np

class EnsembleTrainer:
    """Trainer cho ensemble model"""
    
    def __init__(self):
        """Khá»Ÿi táº¡o trainer"""
        self.models = {}
        self.ensemble_model = None
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        print(f"ğŸš€ Sá»­ dá»¥ng device: {self.device}")
        
        # Cáº¥u hÃ¬nh ensemble
        self.config = {
            'voting_method': 'soft',  # 'hard' hoáº·c 'soft'
            'weights': [0.4, 0.3, 0.3]  # SVM, PhoBERT, BiLSTM
        }
    
    def load_svm_models(self):
        """Load SVM models"""
        print("ğŸ“¥ Loading SVM models...")
        
        try:
            # Level 1 SVM
            with open("models/saved_models/level1_classifier/svm_level1/svm_level1_model.pkl", 'rb') as f:
                svm_level1_data = pickle.load(f)
            
            # Level 2 SVM
            with open("models/saved_models/level2_classifier/svm_level2/svm_level2_model.pkl", 'rb') as f:
                svm_level2_data = pickle.load(f)
            
            self.models['svm'] = {
                'level1': svm_level1_data,
                'level2': svm_level2_data
            }
            
            print("âœ… SVM models loaded successfully")
            return True
            
        except Exception as e:
            print(f"âŒ Lá»—i khi load SVM models: {e}")
            return False
    
    def load_phobert_models(self):
        """Load PhoBERT models"""
        print("ğŸ“¥ Loading PhoBERT models...")
        
        try:
            from transformers import AutoTokenizer, AutoModelForSequenceClassification
            
            # Level 1 PhoBERT
            phobert_level1_path = "models/saved_models/level1_classifier/phobert_level1/phobert_level1_model"
            if Path(phobert_level1_path).exists():
                tokenizer_level1 = AutoTokenizer.from_pretrained(phobert_level1_path)
                model_level1 = AutoModelForSequenceClassification.from_pretrained(phobert_level1_path)
                
                with open(f"{phobert_level1_path}/label_encoder.pkl", 'rb') as f:
                    label_encoder_level1 = pickle.load(f)
                
                self.models['phobert'] = {
                    'level1': {
                        'model': model_level1,
                        'tokenizer': tokenizer_level1,
                        'label_encoder': label_encoder_level1
                    }
                }
            
            # Level 2 PhoBERT
            phobert_level2_path = "models/saved_models/level2_classifier/phobert_level2/phobert_level2_model"
            if Path(phobert_level2_path).exists():
                tokenizer_level2 = AutoTokenizer.from_pretrained(phobert_level2_path)
                model_level2 = AutoModelForSequenceClassification.from_pretrained(phobert_level2_path)
                
                with open(f"{phobert_level2_path}/label_encoder.pkl", 'rb') as f:
                    label_encoder_level2 = pickle.load(f)
                
                if 'phobert' not in self.models:
                    self.models['phobert'] = {}
                
                self.models['phobert']['level2'] = {
                    'model': model_level2,
                    'tokenizer': tokenizer_level2,
                    'label_encoder': label_encoder_level2
                }
            
            print("âœ… PhoBERT models loaded successfully")
            return True
            
        except Exception as e:
            print(f"âŒ Lá»—i khi load PhoBERT models: {e}")
            return False
    
    def load_bilstm_models(self):
        """Load BiLSTM models"""
        print("ğŸ“¥ Loading BiLSTM models...")
        
        try:
            # Level 1 BiLSTM
            with open("models/saved_models/level1_classifier/bilstm_level1/bilstm_level1_model.pkl", 'rb') as f:
                bilstm_level1_data = pickle.load(f)
            
            # Level 2 BiLSTM
            with open("models/saved_models/level2_classifier/bilstm_level2/bilstm_level2_model.pkl", 'rb') as f:
                bilstm_level2_data = pickle.load(f)
            
            self.models['bilstm'] = {
                'level1': bilstm_level1_data,
                'level2': bilstm_level2_data
            }
            
            print("âœ… BiLSTM models loaded successfully")
            return True
            
        except Exception as e:
            print(f"âŒ Lá»—i khi load BiLSTM models: {e}")
            return False
    
    def create_ensemble_predictor(self, level='level1'):
        """Táº¡o ensemble predictor cho má»™t level"""
        print(f"ğŸ—ï¸ Táº¡o ensemble predictor cho {level}...")
        
        estimators = []
        
        # SVM predictor
        if 'svm' in self.models and level in self.models['svm']:
            svm_data = self.models['svm'][level]
            svm_model = svm_data['model']
            svm_vectorizer = svm_data['vectorizer']
            svm_feature_selector = svm_data['feature_selector']
            
            def svm_predict(texts):
                X = svm_vectorizer.transform(texts)
                X_selected = svm_feature_selector.transform(X)
                return svm_model.predict_proba(X_selected)
            
            estimators.append(('svm', svm_predict))
            print("âœ… SVM predictor added")
        
        # PhoBERT predictor
        if 'phobert' in self.models and level in self.models['phobert']:
            phobert_data = self.models['phobert'][level]
            phobert_model = phobert_data['model']
            phobert_tokenizer = phobert_data['tokenizer']
            phobert_label_encoder = phobert_data['label_encoder']
            
            def phobert_predict(texts):
                phobert_model.eval()
                predictions = []
                
                for text in texts:
                    inputs = phobert_tokenizer(
                        text, 
                        truncation=True, 
                        padding=True, 
                        max_length=512, 
                        return_tensors="pt"
                    )
                    
                    with torch.no_grad():
                        outputs = phobert_model(**inputs)
                        probs = torch.softmax(outputs.logits, dim=1)
                        predictions.append(probs.cpu().numpy()[0])
                
                return np.array(predictions)
            
            estimators.append(('phobert', phobert_predict))
            print("âœ… PhoBERT predictor added")
        
        # BiLSTM predictor
        if 'bilstm' in self.models and level in self.models['bilstm']:
            bilstm_data = self.models['bilstm'][level]
            bilstm_model_state = bilstm_data['model_state_dict']
            bilstm_vectorizer = bilstm_data['vectorizer']
            bilstm_label_encoder = bilstm_data['label_encoder']
            bilstm_config = bilstm_data['config']
            
            # Import BiLSTM model class
            from bilstm_colab import BiLSTMClassifier
            
            bilstm_model = BiLSTMClassifier(
                input_size=bilstm_config['max_features'],
                hidden_size=bilstm_config['hidden_size'],
                num_layers=bilstm_config['num_layers'],
                num_classes=len(bilstm_label_encoder.classes_),
                dropout=bilstm_config['dropout']
            )
            
            bilstm_model.load_state_dict(bilstm_model_state)
            bilstm_model.to(self.device)
            bilstm_model.eval()
            
            def bilstm_predict(texts):
                predictions = []
                
                for text in texts:
                    # Vectorize text
                    features = bilstm_vectorizer.transform([text]).toarray()[0]
                    
                    # Truncate/pad
                    if len(features) > bilstm_config['max_length']:
                        features = features[:bilstm_config['max_length']]
                    else:
                        features = np.pad(
                            features, 
                            (0, bilstm_config['max_length'] - len(features)), 
                            'constant'
                        )
                    
                    # Predict
                    with torch.no_grad():
                        inputs = torch.FloatTensor(features).unsqueeze(0).to(self.device)
                        outputs = bilstm_model(inputs)
                        probs = torch.softmax(outputs, dim=1)
                        predictions.append(probs.cpu().numpy()[0])
                
                return np.array(predictions)
            
            estimators.append(('bilstm', bilstm_predict))
            print("âœ… BiLSTM predictor added")
        
        if not estimators:
            print("âŒ KhÃ´ng cÃ³ model nÃ o Ä‘Æ°á»£c load")
            return None
        
        print(f"âœ… Ensemble predictor created vá»›i {len(estimators)} models")
        return estimators
    
    def ensemble_predict(self, texts, level='level1'):
        """Dá»± Ä‘oÃ¡n vá»›i ensemble"""
        print(f"ğŸ”® Ensemble prediction cho {level}...")
        
        estimators = self.create_ensemble_predictor(level)
        if not estimators:
            return None
        
        # Láº¥y predictions tá»« tá»«ng model
        predictions = {}
        for name, predictor in estimators:
            try:
                pred = predictor(texts)
                predictions[name] = pred
                print(f"âœ… {name}: {pred.shape}")
            except Exception as e:
                print(f"âŒ Lá»—i {name}: {e}")
                continue
        
        if not predictions:
            print("âŒ KhÃ´ng cÃ³ prediction nÃ o thÃ nh cÃ´ng")
            return None
        
        # TÃ­nh weighted average
        weights = self.config['weights'][:len(predictions)]
        weights = [w/sum(weights) for w in weights]  # Normalize
        
        ensemble_pred = np.zeros_like(list(predictions.values())[0])
        
        for i, (name, pred) in enumerate(predictions.items()):
            ensemble_pred += weights[i] * pred
        
        # Láº¥y class cÃ³ probability cao nháº¥t
        final_predictions = np.argmax(ensemble_pred, axis=1)
        
        return {
            'predictions': final_predictions,
            'probabilities': ensemble_pred,
            'individual_predictions': predictions
        }
    
    def evaluate_ensemble(self, test_data_path: str):
        """ÄÃ¡nh giÃ¡ ensemble model"""
        print("ğŸ“Š ÄÃ¡nh giÃ¡ ensemble model...")
        
        # Load test data
        df = pd.read_csv(test_data_path, encoding='utf-8')
        texts = df['text'].fillna('').tolist()
        y_true_level1 = df['type_level1'].tolist()
        y_true_level2 = df['domain_level2'].tolist()
        
        # Level 1 prediction
        print("\nğŸ·ï¸ EVALUATION LEVEL 1...")
        level1_results = self.ensemble_predict(texts, 'level1')
        
        if level1_results:
            y_pred_level1 = level1_results['predictions']
            
            # Decode predictions
            if 'svm' in self.models and 'level1' in self.models['svm']:
                label_encoder = self.models['svm']['level1']['label_encoder']
                y_pred_level1_decoded = label_encoder.inverse_transform(y_pred_level1)
                
                # Calculate accuracy
                accuracy_level1 = accuracy_score(y_true_level1, y_pred_level1_decoded)
                print(f"ğŸ“Š Level 1 Accuracy: {accuracy_level1:.4f}")
                print(f"ğŸ“Š Classification Report:")
                print(classification_report(y_true_level1, y_pred_level1_decoded))
        
        # Level 2 prediction
        print("\nğŸ·ï¸ EVALUATION LEVEL 2...")
        level2_results = self.ensemble_predict(texts, 'level2')
        
        if level2_results:
            y_pred_level2 = level2_results['predictions']
            
            # Decode predictions
            if 'svm' in self.models and 'level2' in self.models['svm']:
                label_encoder = self.models['svm']['level2']['label_encoder']
                y_pred_level2_decoded = label_encoder.inverse_transform(y_pred_level2)
                
                # Calculate accuracy
                accuracy_level2 = accuracy_score(y_true_level2, y_pred_level2_decoded)
                print(f"ğŸ“Š Level 2 Accuracy: {accuracy_level2:.4f}")
                print(f"ğŸ“Š Classification Report:")
                print(classification_report(y_true_level2, y_pred_level2_decoded))
        
        # Save ensemble results
        ensemble_path = "models/saved_models/hierarchical_models/ensemble_model.pkl"
        Path(ensemble_path).parent.mkdir(parents=True, exist_ok=True)
        
        ensemble_data = {
            'models': self.models,
            'config': self.config,
            'level1_results': level1_results,
            'level2_results': level2_results
        }
        
        with open(ensemble_path, 'wb') as f:
            pickle.dump(ensemble_data, f)
        
        print(f"ğŸ’¾ Ensemble model Ä‘Ã£ Ä‘Æ°á»£c lÆ°u: {ensemble_path}")
        
        return {
            'level1_results': level1_results,
            'level2_results': level2_results,
            'ensemble_path': ensemble_path
        }

def main():
    """HÃ m chÃ­nh"""
    print("ğŸ‹ï¸ ENSEMBLE TRAINER CHO GOOGLE COLAB!")
    print("=" * 50)
    
    # CÃ i Ä‘áº·t dependencies
    install_deps()
    
    # Táº¡o cáº¥u trÃºc thÆ° má»¥c
    from pathlib import Path
    Path("models/saved_models/hierarchical_models").mkdir(parents=True, exist_ok=True)
    
    # Khá»Ÿi táº¡o trainer
    trainer = EnsembleTrainer()
    
    # Load cÃ¡c models
    print("\nğŸ“¥ LOADING MODELS...")
    svm_loaded = trainer.load_svm_models()
    phobert_loaded = trainer.load_phobert_models()
    bilstm_loaded = trainer.load_bilstm_models()
    
    if not any([svm_loaded, phobert_loaded, bilstm_loaded]):
        print("âŒ KhÃ´ng cÃ³ model nÃ o Ä‘Æ°á»£c load thÃ nh cÃ´ng")
        return
    
    # Evaluation ensemble
    print("\nğŸ“Š EVALUATION ENSEMBLE...")
    results = trainer.evaluate_ensemble("data/processed/dataset_splits/test.csv")
    
    print("\nğŸ‰ ENSEMBLE EVALUATION HOÃ€N THÃ€NH!")
    if results['ensemble_path']:
        print(f"ğŸ“Š Ensemble model: {results['ensemble_path']}")

if __name__ == "__main__":
    main() 