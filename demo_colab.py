#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸš€ Demo viLegalBert cho Google Colab
"""

import os
import sys
import json
import pandas as pd
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

# CÃ i Ä‘áº·t dependencies
def install_deps():
    try:
        import sklearn
        print("âœ… scikit-learn Ä‘Ã£ sáºµn sÃ ng")
    except:
        os.system("pip install scikit-learn")
        print("ğŸ“¦ ÄÃ£ cÃ i Ä‘áº·t scikit-learn")
    
    try:
        import torch
        print("âœ… PyTorch Ä‘Ã£ sáºµn sÃ ng")
    except:
        os.system("pip install torch")
        print("ğŸ“¦ ÄÃ£ cÃ i Ä‘áº·t PyTorch")

# Táº¡o cáº¥u trÃºc thÆ° má»¥c
def create_dirs():
    dirs = ['data/processed', 'models', 'results', 'logs']
    for d in dirs:
        Path(d).mkdir(parents=True, exist_ok=True)
        print(f"âœ… Táº¡o thÆ° má»¥c: {d}")

# Táº¡o dataset máº«u
def create_sample_dataset():
    print("ğŸ“Š Táº¡o dataset máº«u...")
    
    # Dá»¯ liá»‡u máº«u
    sample_data = [
        {
            'id': '001',
            'text': 'Luáº­t vá» quyá»n sá»Ÿ há»¯u trÃ­ tuá»‡ vÃ  báº£o vá»‡ quyá»n lá»£i ngÆ°á»i tiÃªu dÃ¹ng',
            'type_level1': 'LUáº¬T',
            'domain_level2': 'DÃ‚N Sá»°',
            'ministry': 'QUá»C Há»˜I'
        },
        {
            'id': '002', 
            'text': 'Nghá»‹ Ä‘á»‹nh vá» xá»­ pháº¡t vi pháº¡m hÃ nh chÃ­nh trong lÄ©nh vá»±c giao thÃ´ng',
            'type_level1': 'NGHá»Š Äá»ŠNH',
            'domain_level2': 'GIAO THÃ”NG',
            'ministry': 'CHÃNH PHá»¦'
        },
        {
            'id': '003',
            'text': 'ThÃ´ng tÆ° hÆ°á»›ng dáº«n vá» thuáº¿ thu nháº­p cÃ¡ nhÃ¢n vÃ  thuáº¿ giÃ¡ trá»‹ gia tÄƒng',
            'type_level1': 'THÃ”NG TÆ¯',
            'domain_level2': 'THUáº¾',
            'ministry': 'Bá»˜ TÃ€I CHÃNH'
        }
    ]
    
    df = pd.DataFrame(sample_data)
    df.to_csv('data/processed/sample_dataset.csv', index=False, encoding='utf-8')
    print(f"âœ… ÄÃ£ táº¡o dataset máº«u vá»›i {len(df)} samples")
    return df

# Training SVM Ä‘Æ¡n giáº£n
def train_simple_svm():
    print("ğŸ‹ï¸ Training SVM Ä‘Æ¡n giáº£n...")
    
    from sklearn.feature_extraction.text import TfidfVectorizer
    from sklearn.svm import SVC
    from sklearn.model_selection import train_test_split
    from sklearn.metrics import accuracy_score, classification_report
    
    # Load data
    df = pd.read_csv('data/processed/sample_dataset.csv', encoding='utf-8')
    X = df['text']
    y = df['type_level1']
    
    # TF-IDF
    vectorizer = TfidfVectorizer(max_features=1000)
    X_tfidf = vectorizer.fit_transform(X)
    
    # Chia data
    X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.3, random_state=42)
    
    # Training
    svm = SVC(kernel='rbf', random_state=42)
    svm.fit(X_train, y_train)
    
    # Evaluation
    y_pred = svm.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    
    print(f"ğŸ“Š Accuracy: {accuracy:.4f}")
    print(f"ğŸ“Š Classification Report:")
    print(classification_report(y_test, y_pred))
    
    # LÆ°u model
    import pickle
    model_data = {'model': svm, 'vectorizer': vectorizer}
    
    with open('models/svm_model.pkl', 'wb') as f:
        pickle.dump(model_data, f)
    
    print("ğŸ’¾ Model Ä‘Ã£ Ä‘Æ°á»£c lÆ°u: models/svm_model.pkl")
    return svm, vectorizer

# Main function
def main():
    print("ğŸš€ DEMO VILEGALBERT CHO GOOGLE COLAB!")
    print("=" * 50)
    
    # CÃ i Ä‘áº·t dependencies
    install_deps()
    
    # Táº¡o cáº¥u trÃºc
    create_dirs()
    
    # Táº¡o dataset máº«u
    df = create_sample_dataset()
    
    # Training SVM
    model, vectorizer = train_simple_svm()
    
    print("\nğŸ‰ DEMO HOÃ€N THÃ€NH!")
    print("ğŸ“Š Dataset:", len(df), "samples")
    print("ğŸ‹ï¸ Model SVM Ä‘Ã£ Ä‘Æ°á»£c train")
    print("ğŸ’¾ CÃ³ thá»ƒ sá»­ dá»¥ng cho dá»± Ä‘oÃ¡n")

if __name__ == "__main__":
    main() 