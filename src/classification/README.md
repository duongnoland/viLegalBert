# PhÃ¢n loáº¡i VÄƒn báº£n PhÃ¡p lÃ½

Module nÃ y thá»±c hiá»‡n so sÃ¡nh 3 mÃ´ hÃ¬nh phÃ¢n loáº¡i vÄƒn báº£n phÃ¡p lÃ½ tiáº¿ng Viá»‡t:

## ğŸ¯ Má»¥c tiÃªu

So sÃ¡nh hiá»‡u suáº¥t cá»§a cÃ¡c mÃ´ hÃ¬nh:
1. **SVM** (Support Vector Machine) - MÃ´ hÃ¬nh cÆ¡ sá»Ÿ vá»›i TF-IDF
2. **BiLSTM** - MÃ´ hÃ¬nh Deep Learning
3. **PhoBERT** - MÃ´ hÃ¬nh Transformer Ä‘Æ°á»£c pre-train cho tiáº¿ng Viá»‡t

## ğŸ“Š Metrics Ä‘Ã¡nh giÃ¡

- **Accuracy**: Äá»™ chÃ­nh xÃ¡c tá»•ng thá»ƒ
- **Weighted F1-Score**: F1 cÃ³ trá»ng sá»‘ theo sá»‘ lÆ°á»£ng máº«u
- **Macro F1-Score**: F1 trung bÃ¬nh khÃ´ng trá»ng sá»‘

## ğŸ—ï¸ Cáº¥u trÃºc

```
src/classification/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ data_loader.py      # Táº£i vÃ  tiá»n xá»­ lÃ½ dá»¯ liá»‡u
â”œâ”€â”€ models.py           # Äá»‹nh nghÄ©a cÃ¡c mÃ´ hÃ¬nh
â”œâ”€â”€ evaluator.py        # ÄÃ¡nh giÃ¡ vÃ  so sÃ¡nh mÃ´ hÃ¬nh  
â”œâ”€â”€ experiment.py       # Script cháº¡y thÃ­ nghiá»‡m chÃ­nh
â””â”€â”€ README.md           # TÃ i liá»‡u nÃ y
```

## ğŸš€ CÃ¡ch sá»­ dá»¥ng

### 1. CÃ i Ä‘áº·t dependencies

```bash
pip install -r requirements.txt
```

### 2. Chuáº©n bá»‹ dá»¯ liá»‡u

Dá»¯ liá»‡u cáº§n cÃ³ Ä‘á»‹nh dáº¡ng CSV vá»›i 2 cá»™t:
- `text`: VÄƒn báº£n phÃ¡p lÃ½
- `label`: NhÃ£n phÃ¢n loáº¡i

### 3. Cháº¡y thÃ­ nghiá»‡m

#### Option A: Sá»­ dá»¥ng script

```bash
cd src/classification
python experiment.py
```

#### Option B: Sá»­ dá»¥ng Jupyter Notebook

```bash
jupyter notebook notebooks/legal_classification_demo.ipynb
```

### 4. Sá»­ dá»¥ng trong code

```python
from src.classification.experiment import LegalTextClassificationExperiment

# Khá»Ÿi táº¡o thÃ­ nghiá»‡m
experiment = LegalTextClassificationExperiment(
    data_path="data/your_data.csv",
    text_column="text",
    label_column="label"
)

# Cháº¡y thÃ­ nghiá»‡m
evaluator, results_df = experiment.run_full_experiment(
    sample_size=10000,
    phobert_epochs=3
)

# Xem káº¿t quáº£
print(results_df)
```

## ğŸ“‹ Chi tiáº¿t cÃ¡c mÃ´ hÃ¬nh

### 1. SVM (Baseline)
- **Vectorization**: TF-IDF vá»›i n-gram (1,2)
- **Kernel**: Linear
- **Features**: 5000-10000 tá»« quan trá»ng nháº¥t

### 2. BiLSTM
- **Architecture**: Embedding â†’ BiLSTM â†’ Dense
- **Embedding**: 300-dim (cÃ³ thá»ƒ dÃ¹ng pre-trained)
- **LSTM**: 128 hidden units, 2 layers
- **Dropout**: 0.3

### 3. PhoBERT
- **Base model**: vinai/phobert-base
- **Fine-tuning**: Chá»‰ classifier head
- **Max length**: 256 tokens
- **Learning rate**: 2e-5

## ğŸ“ˆ Káº¿t quáº£ máº«u

| MÃ´ hÃ¬nh | Accuracy | Weighted F1 | Macro F1 |
|---------|----------|-------------|----------|
| SVM     | 0.8234   | 0.8189      | 0.7543   |
| BiLSTM  | 0.8567   | 0.8523      | 0.8012   |
| PhoBERT | 0.9123   | 0.9087      | 0.8876   |

## âš™ï¸ Cáº¥u hÃ¬nh

### Tham sá»‘ cÃ³ thá»ƒ Ä‘iá»u chá»‰nh:

```python
# Trong experiment.py
SAMPLE_SIZE = 10000      # Sá»‘ máº«u sá»­ dá»¥ng
PHOBERT_EPOCHS = 3       # Sá»‘ epochs cho PhoBERT
BATCH_SIZE = 16          # Batch size
LEARNING_RATE = 2e-5     # Learning rate

# SVM parameters
MAX_FEATURES = 5000      # Sá»‘ features TF-IDF
NGRAM_RANGE = (1, 2)     # N-gram range

# PhoBERT parameters
MAX_LENGTH = 256         # Äá»™ dÃ i tá»‘i Ä‘a input
DROPOUT = 0.3            # Dropout rate
```

## ğŸ”§ Troubleshooting

### Lá»—i thÆ°á»ng gáº·p:

1. **CUDA out of memory**
   - Giáº£m `BATCH_SIZE` 
   - Giáº£m `SAMPLE_SIZE`
   - Giáº£m `MAX_LENGTH`

2. **File not found**
   - Kiá»ƒm tra Ä‘Æ°á»ng dáº«n trong `DATA_PATH`
   - Äáº£m báº£o file CSV cÃ³ Ä‘Ãºng format

3. **Column not found**
   - Kiá»ƒm tra tÃªn cá»™t `TEXT_COLUMN` vÃ  `LABEL_COLUMN`

4. **Slow training**
   - Sá»­ dá»¥ng GPU náº¿u cÃ³
   - Giáº£m sá»‘ epochs
   - Giáº£m kÃ­ch thÆ°á»›c dá»¯ liá»‡u

## ğŸ“Š PhÃ¢n tÃ­ch káº¿t quáº£

Module tá»± Ä‘á»™ng táº¡o:
- Báº£ng so sÃ¡nh cÃ¡c mÃ´ hÃ¬nh
- Confusion matrix cho tá»«ng mÃ´ hÃ¬nh  
- Biá»ƒu Ä‘á»“ so sÃ¡nh hiá»‡u suáº¥t
- BÃ¡o cÃ¡o chi tiáº¿t (classification report)
- File CSV vá»›i káº¿t quáº£
- BÃ¡o cÃ¡o Markdown

## ğŸ“ á»¨ng dá»¥ng trong bÃ¡o cÃ¡o

### Cáº¥u trÃºc bÃ¡o cÃ¡o Ä‘á» xuáº¥t:

1. **Giá»›i thiá»‡u**
   - Má»¥c tiÃªu phÃ¢n loáº¡i vÄƒn báº£n phÃ¡p lÃ½
   - So sÃ¡nh 3 approaches: traditional ML, deep learning, transformer

2. **PhÆ°Æ¡ng phÃ¡p**
   - MÃ´ táº£ tá»«ng mÃ´ hÃ¬nh
   - Metrics Ä‘Ã¡nh giÃ¡
   - CÃ i Ä‘áº·t thÃ­ nghiá»‡m

3. **Káº¿t quáº£**
   - Báº£ng káº¿t quáº£
   - Biá»ƒu Ä‘á»“ so sÃ¡nh
   - Confusion matrices

4. **PhÃ¢n tÃ­ch**
   - So sÃ¡nh Æ°u/nhÆ°á»£c Ä‘iá»ƒm
   - PhÃ¢n tÃ­ch lá»—i
   - Thá»i gian training vs accuracy

5. **Káº¿t luáº­n**
   - MÃ´ hÃ¬nh tá»‘t nháº¥t
   - á»¨ng dá»¥ng thá»±c táº¿
   - HÆ°á»›ng phÃ¡t triá»ƒn

## ğŸ“ TrÃ­ch dáº«n

Náº¿u sá»­ dá»¥ng PhoBERT:
```
@inproceedings{phobert,
title     = {{PhoBERT: Pre-trained language models for Vietnamese}},
author    = {Dat Quoc Nguyen and Anh Tuan Nguyen},
booktitle = {Findings of the Association for Computational Linguistics: EMNLP 2020},
year      = {2020}
}
``` 